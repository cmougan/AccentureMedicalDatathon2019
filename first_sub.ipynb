{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "before= pd.read_csv(\"./simple.csv\")\n",
    "train = before.query('train==1')\n",
    "test = before.query('train==0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_weights(patient_info, df_aux):\n",
    "    x = np.array(patient_info)\n",
    "    \n",
    "    # weight will always be 1 if we know they are dead\n",
    "    if (x[~np.isnan(x)][0]==1):\n",
    "        x = np.ones_like(x)\n",
    "    else:\n",
    "        y = np.argwhere(~np.isnan(x))\n",
    "        not_zero_index = y.ravel()[0]\n",
    "        \n",
    "        x[:not_zero_index] = 1\n",
    "        x[not_zero_index:] = df_aux['prob'][not_zero_index:]\n",
    "    return (x)\n",
    "\n",
    "\n",
    "'''\n",
    "Function to calculate the weight matrix\n",
    "@paramters\n",
    "    y_df: The test set for which you are calculating the weights\n",
    "        Format: Index = ID, Rows = patients, cols = ['specific_death', 'months_survival']\n",
    "@ return\n",
    "    the weights matrix with the weights for each patient at each time t  \n",
    "'''\n",
    "def calc_weights(y_df):\n",
    "    \n",
    "    # Create a matrix with patient id in the index and months_survival as header, specific_death as values.   \n",
    "    df_y_pivot = y_df.pivot(columns=\"months_survival\", values='specific_death')\n",
    "    # The table changes order of rows after pivoting it, we need to reorder it again by doing reindex_axis.\n",
    "    df_y_pivot= df_y_pivot.reindex(y_df.index, axis=0).reset_index()\n",
    "    \n",
    "    # We need to calculate the weights based on the entire time initially, then cut it off after the fact\n",
    "    all_months_survival = np.arange(0,y_df.months_survival.max()+1)\n",
    "    months_complementary = np.setdiff1d(all_months_survival, y_df.months_survival.unique())\n",
    "    df_complementary = pd.DataFrame(np.nan, index=df_y_pivot.index, columns=months_complementary )\n",
    "    df_y_pivot = pd.concat([df_y_pivot,df_complementary],axis=1)[all_months_survival]\n",
    "    \n",
    "    # Get aux matrix to provide in the get_weights function. \n",
    "    # Probability of being alive at each month based on patients you are certain about (excluding patients censored pior to month)\n",
    "    df_aux = pd.DataFrame(data=np.arange(0,y_df.months_survival.max()+1),columns=[\"months_survival\"])\n",
    "    df_aux['prob_num'] = df_aux['months_survival'].apply(lambda x : (y_df['months_survival'] > x).values.sum())\n",
    "    df_aux['prob_den'] = df_aux['months_survival'].apply(lambda x : ((y_df['months_survival'] < x) & (y_df['specific_death']==1)).values.sum())\n",
    "    df_aux['prob'] = (df_aux['prob_num']/(df_aux['prob_num']+df_aux['prob_den']))\n",
    "\n",
    "    df_aux = df_aux[['months_survival','prob']].sort_values('months_survival').reset_index().drop('index',axis=1)\n",
    "\n",
    "    \n",
    "    #Get weights\n",
    "    df_weights = df_y_pivot.apply(lambda x: get_weights(x,df_aux),axis=1)\n",
    "    \n",
    "    new_weights = pd.DataFrame(np.vstack(df_weights),columns=all_months_survival )\n",
    "\n",
    "    new_weights = np.apply_along_axis(np.cumprod, 1, new_weights)\n",
    "    \n",
    "    new_weights = pd.DataFrame(new_weights)\n",
    "    \n",
    "    return new_weights\n",
    "\n",
    "\n",
    "''' \n",
    "Fill up the Y_true matrix's value \n",
    "You will not need to ever creat the following parameter.\n",
    "It is created (and this is called) within the next function \"populate_actual\".\n",
    "@paramters\n",
    "    patient_info: vector holding every month you want to evaluate, 1 for whichever column months_survived = 1, NA otherwise\n",
    "'''\n",
    "def apply_non_zero(patient_info):\n",
    "    x = np.array(patient_info)\n",
    "    if (x[~np.isnan(x)][0]==0):\n",
    "        x = np.ones_like(x)\n",
    "    else:\n",
    "        y = np.argwhere(~np.isnan(x))\n",
    "        not_zero_index = y.ravel()[0]\n",
    "        x[:(not_zero_index)] = 1\n",
    "        x[(not_zero_index):] = 0   \n",
    "\n",
    "    return (pd.Series(x))\n",
    "\n",
    " \n",
    "'''\n",
    "Build the Y_true matrix\n",
    "@paramters\n",
    "    y_df: The test set for which you are calculating the weights\n",
    "        Format: Index = ID, Rows = patients, cols = ['specific_death', 'months_survival']\n",
    "    years: Number of years for which you want to evaluate your model. Default = 10.\n",
    "'''\n",
    "def populate_actual(y_df, years = 10):\n",
    "    #Create a matrix by pivoting table\n",
    "    df_y_true_pivot = y_df.pivot(columns = \"months_survival\", values='specific_death')\n",
    "    #The table changes order of rows after pivoting it, we need to reorder it again by doing reindex_axis.\n",
    "    df_y_true_pivot = df_y_true_pivot.reindex(y_df.index, axis=0).reset_index()\n",
    "\n",
    "\n",
    "    all_months_survival = np.arange(0,y_df.months_survival.max()+1)\n",
    "    #Get the month that we don't have any patient record in our dataset.\n",
    "    \n",
    "    months_complementary = np.setdiff1d(all_months_survival, y_df.months_survival.unique())\n",
    "    df_complementary = pd.DataFrame(np.nan, index=df_y_true_pivot.index, columns=months_complementary )\n",
    "    \n",
    "    #Add the complementary dataframe to create a full-month dataframe\n",
    "    df_y_true_pivot = pd.concat([df_y_true_pivot,df_complementary],axis=1)[all_months_survival]\n",
    "\n",
    "    # Fill NaN value to either 0 or 1\n",
    "    df_y_pro = df_y_true_pivot.apply(lambda x: apply_non_zero(x),axis=1)\n",
    "    \n",
    "    \n",
    "    chosen_months_survival = np.arange(0,years*12+1)\n",
    "    df_y_pro = df_y_pro[chosen_months_survival].values\n",
    "    \n",
    "    return df_y_pro\n",
    "\n",
    "\n",
    "'''\n",
    "Function to compute the weighted Brier score\n",
    "@paramters\n",
    "    pred: is the prediction matrix\n",
    "        Format: Index = ID, Rows = patients, cols = months, values = probability of being alive (alive = 1, dead = 0)\n",
    "    actual: is the actual value matrix.\n",
    "        Format: Index = ID, Rows = patients, cols = ['specific_death', 'months_survival']\n",
    "    weights: is the matrix of weights associated to the predictions\n",
    "    years_cutoff: is the time for which the error is computed\n",
    "@return\n",
    "    the vector of actual status over time\n",
    "'''\n",
    "def brier_score_loss_weighted(pred, actual, weights, years_cutoff = 10):\n",
    "    \n",
    "    # Select the desired period\n",
    "    weights = weights.iloc[:,:(12*years_cutoff)+1]\n",
    "    \n",
    "    # obtain the unique time values in the y data of your survival data\n",
    "    unique_times = range(0, (12*years_cutoff)+1)\n",
    "    \n",
    "    # fill an empty matrix to hold the weights\n",
    "    errors = np.empty([len(actual), len(unique_times)])\n",
    "    \n",
    "    # subset y_pred to be the number of years you want\n",
    "    m_y_pred = pred.iloc[:,:(max(unique_times)+1)]\n",
    "\n",
    "    try:\n",
    "        m_y_true = np.matrix(populate_actual(actual, years_cutoff))\n",
    "        m_y_pred = np.matrix(m_y_pred)\n",
    "        m_weights = np.matrix(weights)\n",
    "    except:\n",
    "        print(\"Matrix format is required for y_true, y_predict and weights\")\n",
    "            \n",
    "    errors = np.multiply(np.power(m_y_pred - m_y_true,2),m_weights)\n",
    "    \n",
    "    error = pd.DataFrame(errors)\n",
    "    time = years_cutoff * 12\n",
    "    \n",
    "    # calculate the average error of all patients for each time\n",
    "    all_dates = error.mean(axis=0)\n",
    "    \n",
    "    # subset desired dates\n",
    "    desired_dates = pd.DataFrame(all_dates[0:(time+1)])\n",
    "    \n",
    "    # calculate the average error up until a point in time\n",
    "    desired_error = np.mean(desired_dates)\n",
    "    \n",
    "    return desired_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmougan/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "target=train.specific_death\n",
    "target_2=train['months_survival']\n",
    "train.drop(columns=['specific_death','months_survival'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test, y_train, y_test = train_test_split(train, target, stratify = target, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709    0.0\n",
       "1655    0.0\n",
       "185     0.0\n",
       "410     0.0\n",
       "76      0.0\n",
       "1458    0.0\n",
       "270     0.0\n",
       "587     0.0\n",
       "1708    0.0\n",
       "702     0.0\n",
       "2036    0.0\n",
       "2013    0.0\n",
       "520     0.0\n",
       "605     0.0\n",
       "370     0.0\n",
       "523     0.0\n",
       "2074    1.0\n",
       "1649    0.0\n",
       "599     0.0\n",
       "1933    0.0\n",
       "1778    0.0\n",
       "1927    0.0\n",
       "258     0.0\n",
       "813     0.0\n",
       "543     0.0\n",
       "1017    0.0\n",
       "598     1.0\n",
       "321     0.0\n",
       "594     0.0\n",
       "288     0.0\n",
       "       ... \n",
       "726     0.0\n",
       "1862    0.0\n",
       "1742    0.0\n",
       "743     0.0\n",
       "418     1.0\n",
       "653     0.0\n",
       "1931    1.0\n",
       "2009    0.0\n",
       "1852    1.0\n",
       "1766    0.0\n",
       "1039    0.0\n",
       "1807    0.0\n",
       "1445    0.0\n",
       "1102    0.0\n",
       "1117    1.0\n",
       "1669    1.0\n",
       "2134    0.0\n",
       "284     0.0\n",
       "9       0.0\n",
       "464     0.0\n",
       "443     0.0\n",
       "2026    0.0\n",
       "727     0.0\n",
       "586     0.0\n",
       "1303    1.0\n",
       "1594    0.0\n",
       "674     0.0\n",
       "381     0.0\n",
       "162     0.0\n",
       "1678    1.0\n",
       "Name: specific_death, Length: 1718, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_prepare(x_train, y_train, test_df):\n",
    "    \n",
    "    # 3.1. Prepare Y-----\n",
    "    y_train.specific_death = y_train.specific_death.astype(bool)\n",
    "    \n",
    "    # Transform it into a structured array\n",
    "    y_train = y_train.to_records(index = False)\n",
    "    \n",
    "    # 3.2. Prepare X-----\n",
    "    # obtain the x variables that are categorical\n",
    "    categorical_feature_mask = x_train.dtypes==object\n",
    "\n",
    "    # Filter categorical columns using mask and turn it into a list\n",
    "    categorical_cols = x_train.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "    # Ensure categorical columns are category type\n",
    "    for col in categorical_cols:\n",
    "        x_train[col] = x_train[col].astype('category')\n",
    "        test_df[col] = test_df[col].astype('category')\n",
    "    \n",
    "    # 3.3. Fit model-----\n",
    "    # initiate\n",
    "    encoder = OneHotEncoder()\n",
    "    estimator = CoxPHSurvivalAnalysis(alpha=0.01)\n",
    "    \n",
    "    # fit model\n",
    "    estimator.fit(encoder.fit_transform(x_train), y_train)\n",
    "    \n",
    "    # transform the test variables to match the train\n",
    "    x_test = encoder.transform(test_df)\n",
    "    \n",
    "    return (estimator, x_test, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator, x_test, x_train, y_train = fit_and_prepare(train, y_train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_b, x_test_b, x_train_b, y_train_b = fit_and_prepare(b_x_train, b_y_train, b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(x_test, estimator):\n",
    "    \n",
    "    pred_surv = estimator.predict_survival_function(x_test)\n",
    "\n",
    "    # Get the \"X's\" or time of each data point\n",
    "    times = pred_surv[0].x\n",
    "\n",
    "    # Create an empty pandas dataframes with these times as the columns\n",
    "    pred_df = pd.DataFrame(columns = times)\n",
    "\n",
    "    # Convert each row to a pandas series row (transpose) with the index as these x times and append it to the df\n",
    "    for i in range(0, len(x_test)):\n",
    "        pred_df = pred_df.append(pd.DataFrame(pred_surv[i].y).set_index(times).T) \n",
    "\n",
    "    pred_df = pred_df.set_index(x_test.index)\n",
    "\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 store the predictions\n",
    "predictions_b = get_probabilities(x_test_b, estimator_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4.3 Compute estimate of the survival curves\n",
    "pred_curves = estimator_b.predict_survival_function(x_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curve in pred_curves[0:3]:\n",
    "    plt.step(curve.x, curve.y, where=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "prediction = estimator.predict(x_train)\n",
    "result = concordance_index_censored(y_train['specific_death'], \n",
    "                                    y_train[\"months_survival\"],\n",
    "                                    prediction)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "pred_b = estimator_b.predict(x_train_b)\n",
    "result = concordance_index_censored(y_train_b['specific_death'], \n",
    "                                    y_train_b[\"months_survival\"],\n",
    "                                    pred_b)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Please, remember that rows NEED TO BE indexed by patient IDs and columns MUST be ordered from T0 to T120\n",
    "\n",
    "# First subset to 10 years\n",
    "predictions_10yr = predictions_df.iloc[:,:121]\n",
    "\n",
    "#Rename columns to Time periods\n",
    "columns = predictions_10yr.columns.values\n",
    "new_columns = ['T' + str(s) for s in columns]\n",
    "predictions_10yr.columns = new_columns\n",
    "\n",
    "# Write the final CSV file\n",
    "# Please, remember than in order to make the submission you need to create a .zip file ONLY with the csv\n",
    "pd.DataFrame(predictions_10yr).to_csv('sample-submission-cox.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.index = test.index\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 5. Calculate the error #\n",
    "##########################\n",
    "    \n",
    "# To be filled\n",
    "# Using the different module error_functions obtain the error matrix for y_test\n",
    "weights = error_function.calc_weights(predictions_df) \n",
    "\n",
    "error = error_function.brier_score_loss_weighted(pred = predictions,\n",
    "                                                 actual = __, \n",
    "                                                 weights = __, \n",
    "                                                 years_cutoff = __)\n",
    "\n",
    "\n",
    "print(\"Overall error: \", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_score_features(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    scores = np.empty(n_features)\n",
    "    m = CoxPHSurvivalAnalysis()\n",
    "    for j in range(n_features):\n",
    "        Xj = X[:, j:j+1]\n",
    "        m.fit(Xj, y)\n",
    "        scores[j] = m.score(Xj, y)\n",
    "    return scores\n",
    "\n",
    "scores = fit_and_score_features(b_x_train.values, b_y_train)\n",
    "#pd.Series(scores, index=data_x_numeric.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
